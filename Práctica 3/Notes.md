# Notes

- En este fichero guardaremos la tabla en la que indicamos lo que se pide en el guión de prácticas
- Además, hay que añadir una captura de pantalla con las subidas del usuario de *DrivenData*: *Submissions*

# Tabla

| Nombre Propuesta    | Fecha y hora de subida (hora española ) | Posición ocupada | Score Training | Score Test Driven Data |
| ---                 | ---                                     | ---              | ---            | ---                    |
| Primera Propuesta   | 27/12/2021 12:08                        | 793              | -              | 0.8182                 |
| Segunda Propuesta   | 27/12/2021 16:17                        | 398              | 0.8658         | 0.8537                 |
| Tercera Propuesta   | 27/12/2021 21:33                        | 402              | 0.8426         | 0.8536                 |
| Cuarta Propueta     | 28/12/2021 19:12                        | 405              | 0.85966        | 0.8534                 |
| Quinta Propuesta    | 28/12/2021 19:40                        | 339              | 0.8630         | 0.8573                 |
| Sexta Propuesta     | 29/12/2021 00:09                        | 305              | 0.8823         | 0.8589                 |
| Séptima Propueta    | 29/12/2021 13:27                        | 305              | 0.8646         | 0.8589                 |
| Octava Propuesta    | 29/12/2021 14:26                        | 305              | 0.8648         | 0.8589                 |
| Novena Propuesta    | 29/12/2021 18:25                        | 248              | 0.8641         | 0.8604                 |
| Décima Propuesta    | 30/12/2021 18:43                        | 244              | 0.8644         | 0.8607                 |
| Undécima Propuesta  | 30/12/2021 19:08                        | 244              | 0.86452        | 0.8607                 |
| Duodécima Propuesta | 30/12/2021 23:05                        | 199              | 0.8650         | 0.8615                 |
| Propuesta 13        | 31/12/2021 17:55                        | 202              | 0.8643         | 0.8611                 |
| Propuesta 14        | 31/12/2021 18:17                        | 202              | 0.8642         | 0.8602                 |

| Nombre Propuesta    | Descripción  incremental                                                                                                                                                                                                                                                                                                                                                                    | Descripción preprocesado                                                                                                         | Descripción Algoritmo                                                                                                                                                       | Configuración de parámetros                                                                                                                                                                                                                               |
| ---                 | ---                                                                                                                                                                                                                                                                                                                                                                                         | ---                                                                                                                              | ---                                                                                                                                                                         | ---                                                                                                                                                                                                                                                       |
| Primera Propuesta   | Primer modelo funcional. Hacemos lo mínimo para hacer una submission. No tenemos información sobre los resultados en training. Esto se añadirá más tarde                                                                                                                                                                                                                                    | Nos quedamos solo con las variables numéricas, imputamos los missing values usando la mediana                                    | Regresión logística, entrenando dos modelos para las dos variables objetivo                                                                                                 | C = 1, regularización l2                                                                                                                                                                                                                                  |
| Segunda Propuesta   | 1. En vez de eliminar las variables no numéricas, las paso a numéricas usando one hot encoding 2. Normalizamos el conjunto de datos a media 0 y desviación 1 3. Añado separación train / validation para calcular nuestras propias métricas sobre el conjunto etiquetado disponible (que ahora funcionan) 4. Exploramos distintos modelos usando Cross Validation                           | Imputamos missing values con la mediana. Normalizamos a media 0 y desviación 1                                                   | Añadimos cross validation. Decidimos usar AdaBoost                                                                                                                          | lr = 0.5, n_estimators = 200                                                                                                                                                                                                                              |
| Tercera Propuesta   | 1. Borramos outliers con LocalOutlierFactor 2. Imputo valores perdidos con un estimador en vez de con la mediana 3. Añado SMOTE + TomekLinks para balancear las clases                                                                                                                                                                                                                      | Imputamos missing values con un estimador en base a las otras variables. Usamos Smote+TomekLinks                                 | Volvemos a hacer CV y tomamos los mejores parámetros                                                                                                                        | lr = 0.75 n_estimatos = 200                                                                                                                                                                                                                               |
| Cuarta Propueta     | 1. Quitamos SMOTE+Tomek porque empeora los resultados y ralentiza mucho la ejecucucion 2. Añadimos Catboost y ajustamos parametros con CV 3. Añadimos el cacheo del pre-procesado de datos para poder realizar iteraciones mas rapidas                                                                                                                                                      | Borramos SMOTE + TomekLinks, cacheamos el pre-procesado de datos para poder hacer iteraciones más rápidas                        | Añadimos CatBoost y hacemos CV para seleccionar los mejores hiperparámetros                                                                                                 | lr = 0.5, iterations = 20, depth = 4                                                                                                                                                                                                                      |
| Quinta Propuesta    | 1. Añadimos el re-entrenado sobre todo el conjunto de datos después de hacer train + eval en validación 2. Probamos a usar otros parámetros en Catboost, ajustándolos a mano                                                                                                                                                                                                                | Entrenamos sobre todo el conjunto de datos tras entrenar y evaluar en validación                                                 | Catboost al que hemos cambiado manualmente los parámetros                                                                                                                   | lr = 0.5, iterations = 40, depth = 4                                                                                                                                                                                                                      |
| Sexta Propuesta     | 1. Exploramos en CV valores más adecuados para CatBoost 2. Mostramos los resultados de los mejores algoritmos en CV, en un mismo diccionario 3. Añadimos Random Forest y exploramos sus parámetros con Cross Validation                                                                                                                                                                     | -                                                                                                                                | Ajustamos CV para todos los modelos, incluido Random Forest. Sigue siendo el mejor Catboost                                                                                 | lr = 0.25, iterations = 80, depth = 4                                                                                                                                                                                                                     |
| Séptima Propueta    | 1. Hacemos un ensemble con los cuatro modelos explorados, con los mejores parámetros encontrados                                                                                                                                                                                                                                                                                            | -                                                                                                                                | Ensemble con los cuatro algoritmos, con los mejores parámetros que hemos encontrado                                                                                         | Logistic: penalty = "l2", C = 0.05 ; Adaboost: n_estimators = 200, learning_rate = 0.5 ; Catboost: iterations=80, learning_rate=0.25, depth=4 ; Random Forest:     n_estimators = 200, criterion = "entropy", min_samples_split = 4, min_samples_leaf = 3 |
| Octava Propuesta    | 1. Entrenamos los clasificadores por separado. Usamos los resultados en nuestro test para ponderar los clasificadores del ensemble usando softmax                                                                                                                                                                                                                                           | -                                                                                                                                | Ponderamos el ensemble con los resultados de los modelos individuales, en validación, aplicando softmax                                                                     | -                                                                                                                                                                                                                                                         |
| Novena Propuesta    | 1. Añadimos IsolationForest para la detección de outliers 2. Corregimos un error (estabamos clasificando con Catboost antiguo y no con el ensemble)                                                                                                                                                                                                                                         | Además del borrado de outliers que teníamos, añado IsolationForest para borrar outliers                                          | Aplicamos correctamente el ensemble (estábamos re-entrenando con un Catboost simple)                                                                                        | -                                                                                                                                                                                                                                                         |
| Décima Propuesta    | 1. Usamos imputador de missing values por la mediana 2. Añado Extreme Random Forest como modelo a tener en cuenta 3. Añado MLP como modelo a tener en cuenta 3. Afino algo los parámetros explorados en CV de los modelos ya explorados y de los nuevos modelos añadidos 4. Hago CV para sacar buenos parámetros de estos dos modelos 5. Construyo el ensemble añadiendo los nuevos modelos | En vez de usar imputación con estimador, imputamos usando la mediana                                                             | Añadimos Extreme Random Forest y MLP. Hacemos hyperparamter tuning de todos los algoritmos que llevamos explorados hasta ahora. Añadimos los dos nuevos modelos al ensemble | Mismos parámetros para modelos ya explorados. Extreme random forest: n\estimators: 300, min\_samples\_split: 2, min\_samples\_leaf: 3. MLP: alpha: 0.1, learning_rate_init: 0.0001                                                                        |
| Undécima Propuesta  | 1. Para realizar la normalización de datos, hacemos data snooping escalando usando                                                                                                                                                                                                                                                                                                          | En la normalización de datos, aprendemos los parámetros usando training, validación y test                                       | -                                                                                                                                                                           | -                                                                                                                                                                                                                                                         |
| Duodécima Propuesta | 1. Deshago el data snooping 2. Añado xgboost 3. Busco sus mejores parámetros con Cross Validation                                                                                                                                                                                                                                                                                           | Deshago la normalización de datos usando todos los conjuntos. Solo uso el conjunto de entrenamiento para aprender los parámetros | Añado XGBOOST. Exploro sus parámetros con CV. Lo añado al ensemble de modelos                                                                                               | XGBOOST: max_depth: 4, eta: 0.15                                                                                                                                                                                                                          |
| Propuesta 13        | 1. En vez de usar los pesos en sí, uso su ranking inverso                                                                                                                                                                                                                                                                                                                                   | -                                                                                                                                | Uso ranking en vez de softmax para realizar la asignación de pesos                                                                                                          | -                                                                                                                                                                                                                                                         |
| Propuesta 14        | 1. Vuelvo a usar softmax para los pesos 2. Solo uso catboost, MLP y xgboost en el ensemble                                                                                                                                                                                                                                                                                                  | -                                                                                                                                | Uso solo MLP, Catboost y Xgboost para el ensemble. Volvemos a usar softmax para los pesos del ensemble, en vez del ranking                                                  | -                                                                                                                                                                                                                                                         |

# Por cada subida

- Por cada subida hay que guardar:
    1. Script de python usado para obtener los resultados de la subida
    2. Fichero `.csv` con la clasificación que hemos realizado


