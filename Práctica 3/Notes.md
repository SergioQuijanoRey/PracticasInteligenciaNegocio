# Notes

- En este fichero guardaremos la tabla en la que indicamos lo que se pide en el guión de prácticas
- Además, hay que añadir una captura de pantalla con las subidas del usuario de *DrivenData*: *Submissions*

# Tabla

| Nombre Propuesta  | Fecha y hora de subida (hora española ) | Posición ocupada | Score Training | Score Test Driven Data | Descripción incremental                                                                                                                                                                                                                                                                                                                                           | Descripción preprocesado                                                                                  | Descripción Algoritmo                                                                                   | Configuración de parámetros                                                                                                                                                                                                                               |
| ---               | ---                                     | ---              | ---            | ---                    | ---                                                                                                                                                                                                                                                                                                                                                               | ---                                                                                                       | ---                                                                                                     | ---                                                                                                                                                                                                                                                       |
| Primera Propuesta | 27/12/2021 12:08                        | 793              | -              | 0.8182                 | Primer modelo funcional. Hacemos lo mínimo para hacer una submission. No tenemos información sobre los resultados en training. Esto se añadirá más tarde                                                                                                                                                                                                          | Nos quedamos solo con las variables numéricas, imputamos los missing values usando la mediana             | Regresión logística, entrenando dos modelos para las dos variables objetivo                             | C = 1, regularización l2                                                                                                                                                                                                                                  |
| Segunda Propuesta | 27/12/2021 16:17                        | 398              | 0.8658         | 0.8537                 | 1. En vez de eliminar las variables no numéricas, las paso a numéricas usando one hot encoding 2. Normalizamos el conjunto de datos a media 0 y desviación 1 3. Añado separación train / validation para calcular nuestras propias métricas sobre el conjunto etiquetado disponible (que ahora funcionan) 4. Exploramos distintos modelos usando Cross Validation | Imputamos missing values con la mediana. Normalizamos a media 0 y desviación 1                            | Añadimos cross validation. Decidimos usar AdaBoost                                                      | lr = 0.5, n_estimators = 200                                                                                                                                                                                                                              |
| Tercera Propuesta | 27/12/2021 21:33                        | 402              | 0.8426         | 0.8536                 | 1. Borramos outliers con LocalOutlierFactor 2. Imputo valores perdidos con un estimador en vez de con la mediana 3. Añado SMOTE + TomekLinks para balancear las clases                                                                                                                                                                                            | Imputamos missing values con un estimador en base a las otras variables. Usamos Smote+TomekLinks          | Volvemos a hacer CV y tomamos los mejores parámetros                                                    | lr = 0.75 n_estimatos = 200                                                                                                                                                                                                                               |
| Cuarta Propueta   | 28/12/2021 19:12                        | 405              | 0.85966        | 0.8534                 | 1. Quitamos SMOTE+Tomek porque empeora los resultados y ralentiza mucho la ejecucucion 2. Añadimos Catboost y ajustamos parametros con CV 3. Añadimos el cacheo del pre-procesado de datos para poder realizar iteraciones mas rapidas                                                                                                                            | Borramos SMOTE + TomekLinks, cacheamos el pre-procesado de datos para poder hacer iteraciones más rápidas | Añadimos CatBoost y hacemos CV para seleccionar los mejores hiperparámetros                             | lr = 0.5, iterations = 20, depth = 4                                                                                                                                                                                                                      |
| Quinta Propuesta  | 28/12/2021 19:40                        | 339              | 0.8630         | 0.8573                 | 1. Añadimos el re-entrenado sobre todo el conjunto de datos después de hacer train + eval en validación 2. Probamos a usar otros parámetros en Catboost, ajustándolos a mano                                                                                                                                                                                      | Entrenamos sobre todo el conjunto de datos tras entrenar y evaluar en validación                          | Catboost al que hemos cambiado manualmente los parámetros                                               | lr = 0.5, iterations = 40, depth = 4                                                                                                                                                                                                                      |
| Sexta Propuesta   | 29/12/2021 00:09                        | 305              | 0.8823         | 0.8589                 | 1. Exploramos en CV valores más adecuados para CatBoost 2. Mostramos los resultados de los mejores algoritmos en CV, en un mismo diccionario 3. Añadimos Random Forest y exploramos sus parámetros con Cross Validation                                                                                                                                           | -                                                                                                         | Ajustamos CV para todos los modelos, incluido Random Forest. Sigue siendo el mejor Catboost             | lr = 0.25, iterations = 80, depth = 4                                                                                                                                                                                                                     |
| Séptima Propueta  | 29/12/2021 13:27                        | 305              | 0.8646         | 0.8589                 | 1. Hacemos un ensemble con los cuatro modelos explorados, con los mejores parámetros encontrados                                                                                                                                                                                                                                                                  | -                                                                                                         | Ensemble con los cuatro algoritmos, con los mejores parámetros que hemos encontrado                     | Logistic: penalty = "l2", C = 0.05 ; Adaboost: n_estimators = 200, learning_rate = 0.5 ; Catboost: iterations=80, learning_rate=0.25, depth=4 ; Random Forest:     n_estimators = 200, criterion = "entropy", min_samples_split = 4, min_samples_leaf = 3 |
| Octava Propuesta  | 29/12/2021 14:26                        | 305              | 0.8648         | 0.8589                 | 1. Entrenamos los clasificadores por separado. Usamos los resultados en nuestro test para ponderar los clasificadores del ensemble usando softmax                                                                                                                                                                                                                 | -                                                                                                         | Ponderamos el ensemble con los resultados de los modelos individuales, en validación, aplicando softmax | Logistic: penalty = "l2", C = 0.05 ; Adaboost: n_estimators = 200, learning_rate = 0.5 ; Catboost: iterations=80, learning_rate=0.25, depth=4 ; Random Forest:     n_estimators = 200, criterion = "entropy", min_samples_split = 4, min_samples_leaf = 3 |



# Por cada subida

- Por cada subida hay que guardar:
    1. Script de python usado para obtener los resultados de la subida
    2. Fichero `.csv` con la clasificación que hemos realizado
